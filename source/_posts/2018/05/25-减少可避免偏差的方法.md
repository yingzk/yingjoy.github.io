---
title: 25. 减少可避免偏差的方法
date: 2018-05-14 01:06:00
en_title: Techniques for reducing avoidable bias
tags: [Machine Learning Yearning, Machine Learning, AI]
---

如果你的学习算法是高可避免偏差的话，你可以尝试以下办法:

• 增加模型大小 (如神经元和层数): 该方法可以减少偏差，因为它可以让你更好的适应训练集。如果你发现该方法增加了方差，那么使用正则化方法，它通常可以消除方差的增加。

• 基于错误分析修改输入特征: 假设错误分析启发你去创建额外的特征，以帮助算法消除特定类别的错误。（我们将在下一章进一步讨论）这些新特征可能有助于减少偏差和方差。理论上来说，增加更多的特征可能会增加方差，如果你发现方差增加了，那么使用正则化的方法，它通常可以消除方差的增加。

• 减少或消除正则化： (L2 正则化, L1 正则化, dropout): 这将减少可避免的偏差，但会增加方差。

• 修改模型架构： (如神经网络架构) 以便算法更加适用于你的问题：这种方法可能会同时影响偏差和方差。

下面的方法是没有用的:

• 添加更多的训练数据: 这种方法有助于减少方差问题，但是它通常对偏差没有显著的影响。
